{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Sub-activity: Loading and pre-processing of text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_turing_award_recipients():\n",
    "    endpoint = \"https://www.wikidata.org/w/api.php\"\n",
    "    \n",
    "    entity_ID_params = {\n",
    "        \"action\":\"query\",\n",
    "        \"format\":\"json\",\n",
    "        \"list\":\"search\",\n",
    "        \"srprop\":\"sectiontitle\",\n",
    "        \"srsearch\": \"haswbstatement:P166=Q185667\",\n",
    "        \"srlimit\":100\n",
    "    }\n",
    "    entity_ID_response = requests.get(endpoint, params=entity_ID_params)\n",
    "    entity_ID_data = entity_ID_response.json()\n",
    "    \n",
    "    entity_IDs = [entity_ID[\"title\"] for entity_ID in entity_ID_data['query']['search']]\n",
    "    \n",
    "    # Since the results of the entity name mix with different languages, I need to use the IDs to get the laureates' English names\n",
    "    entity_names = []\n",
    "    for entity_ID in entity_IDs:\n",
    "        url = \"{}?action=wbgetentities&format=json&ids={}&sites=&props=labels&languages=en\".format(endpoint, entity_ID)\n",
    "    \n",
    "        entity_name_response = requests.get(url)\n",
    "        entity_name_data = entity_name_response.json()\n",
    "        entity_names.append(entity_name_data['entities'][entity_ID]['labels']['en']['value'])\n",
    "\n",
    "    return dict(zip(entity_IDs, entity_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = get_turing_award_recipients()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Q80': 'Tim Berners-Lee', 'Q3572699': 'Yoshua Bengio', 'Q92894': 'Geoffrey Hinton', 'Q17457': 'Donald Knuth', 'Q92612': 'Richard M. Karp', 'Q92638': 'Robert Tarjan', 'Q92743': 'Vint Cerf', 'Q92824': 'Judea Pearl', 'Q181529': 'Herbert Simon', 'Q204815': 'Marvin Minsky', 'Q578036': 'Ron Rivest', 'Q92794': 'Jeffrey David Ullman', 'Q92739': 'John McCarthy', 'Q49823': 'Dana Scott', 'Q92602': 'Tony Hoare', 'Q3571662': 'Yann LeCun', 'Q92626': 'Manuel Blum', 'Q92758': 'Michael Stonebraker', 'Q16080922': 'Barbara Liskov', 'Q62870': 'Stephen Cook', 'Q8556': 'Edsger W. Dijkstra', 'Q92604': 'Niklaus Wirth', 'Q357965': 'Michael O. Rabin', 'Q11609': 'Shafrira Goldwasser', 'Q92609': 'Fred Brooks', 'Q439245': 'Allen Newell', 'Q92670': 'Jack Dongarra', 'Q92819': 'Edmund M. Clarke', 'Q92851': 'David A. Patterson', 'Q92613': 'Leslie Lamport', 'Q62874': 'John Edward Hopcroft', 'Q92854': 'John L. Hennessy', 'Q92628': 'Juris Hartmanis', 'Q7143512': 'Pat Hanrahan', 'Q62861': 'Alan Perlis', 'Q320624': 'Adi Shamir', 'Q45575': 'Dennis M. Ritchie', 'Q1107006': 'Ken Thompson', 'Q92614': 'Douglas Engelbart', 'Q62888': 'Andrew Yao', 'Q93080': 'Silvio Micali', 'Q476466': 'Martin Edward Hellman', 'Q92820': 'Raj Reddy', 'Q92649': 'Amir Pnueli', 'Q62898': 'Alfred Aho', 'Q92641': 'Robert W. Floyd', 'Q92742': 'Alan Kay', 'Q93154': 'Leslie Valiant', 'Q62843': 'Bob Kahn', 'Q92643': 'Robin Milner', 'Q92823': 'Edward Feigenbaum', 'Q462089': 'Whitfield Diffie', 'Q62866': 'Ivan Sutherland', 'Q92629': 'Kenneth E. Iverson', 'Q92618': 'Peter Naur', 'Q92822': 'Richard E. Stearns', 'Q92596': 'Edgar F. Codd', 'Q92746': 'John Backus', 'Q918650': 'Leonard Adleman', 'Q62857': 'Maurice Wilkes', 'Q92619': 'Richard Hamming', 'Q92821': 'E. Allen Emerson', 'Q62877': 'James H. Wilkinson', 'Q92782': 'William Kahan', 'Q92632': 'John Cocke', 'Q93161': 'Edwin Catmull', 'Q92744': 'Kristen Nygaard', 'Q92606': 'Jim Gray', 'Q92781': 'Iosif Sifakis', 'Q9602': 'Frances E. Allen', 'Q92625': 'Fernando J. Corbat√≥', 'Q62894': 'Charles Bachman', 'Q92644': 'Butler Lampson', 'Q92745': 'Ole-Johan Dahl', 'Q92828': 'Charles P. Thacker'}\n"
     ]
    }
   ],
   "source": [
    "print(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wikipedia_content():\n",
    "    endpoint = \"https://www.wikipedia.org/w/api.php\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "award_winners = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Sub-activity: Applying NLP operations on the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Finding synonyms and antonyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4 Bigrams and trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Sub-section: Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Barplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
