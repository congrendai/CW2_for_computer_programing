{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from nltk import FreqDist\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from matplotlib import pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Sub-activity: Loading and pre-processing of text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "WIKIDATA_API_ENDPOINT = \"https://www.wikidata.org/w/api.php\"\n",
    "\n",
    "WIKIDATA_COMMON_PARAMS = {\n",
    "    \"ids\":\"\",\n",
    "    \"props\": \"\",\n",
    "    \"format\":\"json\",\n",
    "    \"languages\": \"en\",\n",
    "    \"formatversion\": \"2\",\n",
    "    \"sitefilter\": \"enwiki\",\n",
    "    \"action\": \"wbgetentities\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_turing_award_recipients():\n",
    "\n",
    "    wikidata_entity_params = {\n",
    "        \"srlimit\":100,\n",
    "        \"format\":\"json\",\n",
    "        \"list\":\"search\",\n",
    "        \"action\":\"query\",\n",
    "        \"formatversion\": \"2\",\n",
    "        \"srprop\":\"sectiontitle\",\n",
    "        \"srsearch\": \"haswbstatement:P166=Q185667\",\n",
    "    }\n",
    "    \n",
    "    wikidata_ID_response = requests.get(WIKIDATA_API_ENDPOINT, params = wikidata_entity_params)\n",
    "    wikidata_ID_data = wikidata_ID_response.json()    \n",
    "    wikidata_IDs = [entity_ID[\"title\"] for entity_ID in wikidata_ID_data[\"query\"][\"search\"]]\n",
    "\n",
    "    return wikidata_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1257,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidata_IDs = get_turing_award_recipients()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wikipedia_content(wikidata_ID):\n",
    "    wikipedia_API_endpoint = \"https://en.wikipedia.org/w/api.php\"\n",
    "    \n",
    "    WIKIDATA_COMMON_PARAMS[\"ids\"] = wikidata_ID\n",
    "    WIKIDATA_COMMON_PARAMS[\"props\"] = \"sitelinks\"\n",
    "    \n",
    "    wikidata_response = requests.get(WIKIDATA_API_ENDPOINT, params = WIKIDATA_COMMON_PARAMS)\n",
    "    wikidata_response_data = wikidata_response.json()\n",
    "\n",
    "    # To extract content from the wikipidia page, we have to use titles gained the wikidata IDs, since the titles of wikipedia pages are unique.\n",
    "    wikidata_title = wikidata_response_data[\"entities\"][wikidata_ID][\"sitelinks\"][\"enwiki\"][\"title\"]    \n",
    "\n",
    "    wikipedia_params = {\n",
    "        \"titles\": \"\",\n",
    "        \"format\": \"json\",\n",
    "        \"action\": \"query\",\n",
    "        \"prop\": \"extracts\",\n",
    "        \"formatversion\": \"2\",\n",
    "        \"titles\": wikidata_title,\n",
    "        \"exsectionformat\": \"wiki\"\n",
    "    }\n",
    "    \n",
    "    wikipedia_content_response = requests.get(wikipedia_API_endpoint, params = wikipedia_params)\n",
    "    wikipedia_content_data = wikipedia_content_response.json()\n",
    "    wikipedia_content = wikipedia_content_data[\"query\"][\"pages\"][0][\"extract\"]\n",
    "    return wikipedia_content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_award_winners_info(wikidata_ID):\n",
    "    \n",
    "    WIKIDATA_COMMON_PARAMS[\"ids\"] = wikidata_ID\n",
    "    WIKIDATA_COMMON_PARAMS[\"props\"] = \"claims|sitelinks\"\n",
    "\n",
    "    wikidata_title_response = requests.get(WIKIDATA_API_ENDPOINT, params = WIKIDATA_COMMON_PARAMS)\n",
    "    wikidata_title_data = wikidata_title_response.json()\n",
    "\n",
    "    # Extract name\n",
    "    try:\n",
    "        wikidata_name = wikidata_title_data[\"entities\"][wikidata_ID][\"sitelinks\"][\"enwiki\"][\"title\"]\n",
    "    except KeyError:\n",
    "        wikidata_name = None\n",
    "\n",
    "    # Extract intro from wikipedia page\n",
    "    try:\n",
    "        wikipedia_content = get_wikipedia_content(wikidata_ID)\n",
    "    except KeyError:\n",
    "        wikipedia_intro = None\n",
    "    else:\n",
    "        content_remove_newline_to_space = wikipedia_content.replace(\"\\n\", \" \")\n",
    "        content_with_p_tag = re.sub(r\"<\\/?(?!p)\\w*\\b[^>]*>\", \"\", content_remove_newline_to_space.split(\"<h2>\")[0])\n",
    "        paragraphs = re.findall(r'<p>(.+?)</p>', content_with_p_tag)\n",
    "        wikipedia_intro = \"\\n\".join(paragraphs)\n",
    "\n",
    "    # Extract gender ID to get gender from \"sex or gender (P21)\"\n",
    "    try:\n",
    "        wikidata_gender_id = wikidata_title_data[\"entities\"][wikidata_ID][\"claims\"][\"P21\"][0][\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"]\n",
    "    except KeyError:\n",
    "        wikidata_gender_id = None\n",
    "        \n",
    "    # Get birth date from \"date of birth (P569)\"\n",
    "    try:\n",
    "        wikidata_birth_date = wikidata_title_data[\"entities\"][wikidata_ID][\"claims\"][\"P569\"][0][\"mainsnak\"][\"datavalue\"][\"value\"][\"time\"].split(\"T\")[0].split(\"+\")[1]\n",
    "    except KeyError:\n",
    "        wikidata_birth_date = None\n",
    "\n",
    "    # Extract birth place ID to get birth place from \"place of birth (P19)\"\n",
    "    try:\n",
    "        wikidata_birth_place = wikidata_title_data[\"entities\"][wikidata_ID][\"claims\"][\"P19\"][0][\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"]\n",
    "    except KeyError:\n",
    "        wikidata_birth_place = None\n",
    "\n",
    "    # Extract employer ID to get employer from \"employer (P108)\"\n",
    "    # employer ID is inside of \"mainsnak\" key\n",
    "    try:\n",
    "        wikidata_employer_mainsnaks = wikidata_title_data[\"entities\"][wikidata_ID][\"claims\"][\"P108\"]\n",
    "    except KeyError:\n",
    "        wikidata_employers_IDs = None\n",
    "    else:\n",
    "        wikidata_employers_IDs = [wikidata_employer_ID[\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"] for wikidata_employer_ID in wikidata_employer_mainsnaks]\n",
    "        \n",
    "    # Extract educated at ID to get educated at from \"educated at (P69)\"\n",
    "    # educated at ID is inside of \"mainsnak\" key\n",
    "    try:\n",
    "        wikidata_educated_at_mainsnaks = wikidata_title_data[\"entities\"][wikidata_ID][\"claims\"][\"P69\"]\n",
    "    except KeyError:\n",
    "        wikidata_educated_at_IDs = None\n",
    "    else:\n",
    "        wikidata_educated_at_IDs = [wikidata_educated_at_ID[\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"] for wikidata_educated_at_ID in wikidata_educated_at_mainsnaks]\n",
    "\n",
    "    # Join the IDs per person that we want to get info from into a list\n",
    "    entity_info_request_IDs = [wikidata_gender_id, wikidata_birth_place, \"|\".join(wikidata_employers_IDs), \"|\".join(wikidata_educated_at_IDs)]\n",
    "    \n",
    "    # A list that contains all the info of the person\n",
    "    \n",
    "    entity_info = [wikidata_name, wikipedia_intro, wikidata_birth_date]\n",
    "\n",
    "    WIKIDATA_COMMON_PARAMS[\"props\"] = \"labels\"\n",
    "    for i in range(len(entity_info_request_IDs)):\n",
    "        entity_values = []\n",
    "        \n",
    "        WIKIDATA_COMMON_PARAMS[\"ids\"] = entity_info_request_IDs[i]\n",
    "        \n",
    "        response = requests.get(WIKIDATA_API_ENDPOINT, params = WIKIDATA_COMMON_PARAMS)\n",
    "        data = response.json()\n",
    "\n",
    "        if i == 0 or i == 1:\n",
    "            try:\n",
    "                entity_value = data[\"entities\"][entity_info_request_IDs[i]][\"labels\"][\"en\"][\"value\"]\n",
    "            except KeyError:\n",
    "                entity_info.append(None)\n",
    "            else:\n",
    "                entity_info.append(entity_value)\n",
    "\n",
    "        else:\n",
    "            try:\n",
    "                entity_IDs = entity_info_request_IDs[i].split(\"|\")\n",
    "            except AttributeError:\n",
    "                entity_IDs = []\n",
    "\n",
    "            for entity_ID in entity_IDs:\n",
    "                try:\n",
    "                    entity_value = data[\"entities\"][entity_ID][\"labels\"][\"en\"][\"value\"]\n",
    "                except KeyError:\n",
    "                    entity_values.append(None)\n",
    "                else:\n",
    "                    entity_values.append(entity_value)\n",
    "            \n",
    "            entity_info.append(entity_values)\n",
    "    \n",
    "    return entity_info[0], entity_info[1], entity_info[2], entity_info[3], entity_info[4], entity_info[5], entity_info[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1260,
   "metadata": {},
   "outputs": [],
   "source": [
    "award_winners = {\n",
    "    \"name\": [],\n",
    "    \"intro\": [],\n",
    "    \"birth_date\": [],\n",
    "    \"gender\": [],\n",
    "    \"birth_place\": [],\n",
    "    \"employer\": [],\n",
    "    \"educated_at\": []\n",
    "}\n",
    "\n",
    "for wikidata_ID in wikidata_IDs:\n",
    "    wikidata_name, wikipedia_intro, wikidata_birth_date, wikidata_gender, wikidata_birth_place, wikidata_employer, wikidata_educated_at = get_award_winners_info(wikidata_ID)\n",
    "    award_winners[\"name\"].append(wikidata_name)\n",
    "    award_winners[\"intro\"].append(wikipedia_intro)\n",
    "    award_winners[\"birth_date\"].append(wikidata_birth_date)\n",
    "    award_winners[\"gender\"].append(wikidata_gender)\n",
    "    award_winners[\"birth_place\"].append(wikidata_birth_place)\n",
    "    award_winners[\"employer\"].append(wikidata_employer)\n",
    "    award_winners[\"educated_at\"].append(wikidata_educated_at)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The names of all award winners are (alphabetical order): \n",
      "\n",
      "Adi Shamir, Alan Kay, Alan Perlis, Alfred Aho, Allen Newell, Amir Pnueli, Andrew Yao, Barbara Liskov, Bob Kahn, Butler Lampson, Charles Bachman, Charles P. Thacker, Dana Scott, David Patterson (computer scientist), Dennis Ritchie, Donald Knuth, Douglas Engelbart, E. Allen Emerson, Edgar F. Codd, Edmund M. Clarke, Edsger W. Dijkstra, Edward Feigenbaum, Edwin Catmull, Fernando J. Corbató, Frances Allen, Fred Brooks, Geoffrey Hinton, Herbert A. Simon, Ivan Sutherland, Jack Dongarra, James H. Wilkinson, Jeffrey Ullman, Jim Gray (computer scientist), John Backus, John Cocke (computer scientist), John Hopcroft, John L. Hennessy, John McCarthy (computer scientist), Joseph Sifakis, Judea Pearl, Juris Hartmanis, Ken Thompson, Kenneth E. Iverson, Kristen Nygaard, Leonard Adleman, Leslie Lamport, Leslie Valiant, Manuel Blum, Martin Hellman, Marvin Minsky, Maurice Wilkes, Michael O. Rabin, Michael Stonebraker, Niklaus Wirth, Ole-Johan Dahl, Pat Hanrahan, Peter Naur, Raj Reddy, Richard E. Stearns, Richard Hamming, Richard M. Karp, Robert Tarjan, Robert W. Floyd, Robin Milner, Ron Rivest, Shafi Goldwasser, Silvio Micali, Stephen Cook, Tim Berners-Lee, Tony Hoare, Vint Cerf, Whitfield Diffie, William Kahan, Yann LeCun, Yoshua Bengio.\n"
     ]
    }
   ],
   "source": [
    "print(\"The names of all award winners are (alphabetical order): \\n\\n{}.\".format(\", \".join(sorted(award_winners[\"name\"]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1262,
   "metadata": {},
   "outputs": [],
   "source": [
    "award_winners_intro = pd.DataFrame(columns = [\"winner_name\", \"count_words\", \"count_sentences\", \"count_paragraphs\", \"common_words\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>winner_name</th>\n",
       "      <th>count_words</th>\n",
       "      <th>count_sentences</th>\n",
       "      <th>count_paragraphs</th>\n",
       "      <th>common_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tim Berners-Lee</td>\n",
       "      <td>359</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>the, of, and, He, a, is, Web, as, World, Wide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yoshua Bengio</td>\n",
       "      <td>91</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>and, the, of, for, Bengio, is, a, work, deep, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Geoffrey Hinton</td>\n",
       "      <td>181</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>the, and, of, for, in, Hinton, a, his, to, is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Donald Knuth</td>\n",
       "      <td>184</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>the, of, and, Knuth, computer, is, to, He, ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Richard M. Karp</td>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>in, and, the, of, for, Karp, is, computer, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Fernando J. Corbató</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a, Fernando, José, \"Corby\", Corbató, (July, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Charles Bachman</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>his, Bachman, was, an, in, of, Charles, Willia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Butler Lampson</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Butler, W., Lampson,, ForMemRS,, (born, Decemb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Ole-Johan Dahl</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>of, Dahl, was, a, computer, the, and, Ole-Joha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Charles P. Thacker</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>computer, the, Charles, Patrick, \"Chuck\", Thac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            winner_name  count_words  count_sentences  count_paragraphs  \\\n",
       "0       Tim Berners-Lee          359               17                 4   \n",
       "1         Yoshua Bengio           91                4                 2   \n",
       "2       Geoffrey Hinton          181                8                 3   \n",
       "3          Donald Knuth          184                8                 3   \n",
       "4       Richard M. Karp           92                3                 2   \n",
       "..                  ...          ...              ...               ...   \n",
       "70  Fernando J. Corbató           28                1                 1   \n",
       "71      Charles Bachman           57                3                 1   \n",
       "72       Butler Lampson           27                1                 1   \n",
       "73       Ole-Johan Dahl           44                2                 1   \n",
       "74   Charles P. Thacker           35                2                 1   \n",
       "\n",
       "                                         common_words  \n",
       "0       the, of, and, He, a, is, Web, as, World, Wide  \n",
       "1   and, the, of, for, Bengio, is, a, work, deep, ...  \n",
       "2       the, and, of, for, in, Hinton, a, his, to, is  \n",
       "3   the, of, and, Knuth, computer, is, to, He, ana...  \n",
       "4   in, and, the, of, for, Karp, is, computer, the...  \n",
       "..                                                ...  \n",
       "70  a, Fernando, José, \"Corby\", Corbató, (July, 1,...  \n",
       "71  his, Bachman, was, an, in, of, Charles, Willia...  \n",
       "72  Butler, W., Lampson,, ForMemRS,, (born, Decemb...  \n",
       "73  of, Dahl, was, a, computer, the, and, Ole-Joha...  \n",
       "74  computer, the, Charles, Patrick, \"Chuck\", Thac...  \n",
       "\n",
       "[75 rows x 5 columns]"
      ]
     },
     "execution_count": 1263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "award_winners_intro[\"winner_name\"] = award_winners[\"name\"]\n",
    "award_winners_intro[\"count_words\"] = pd.DataFrame(award_winners[\"intro\"]).apply(lambda x: x[0].split(), axis = 1).apply(lambda x: len(x))\n",
    "award_winners_intro[\"count_sentences\"] = pd.DataFrame(award_winners[\"intro\"]).apply(lambda x: sent_tokenize(x[0]), axis = 1).apply(lambda x: len(x))\n",
    "award_winners_intro[\"count_paragraphs\"] = pd.DataFrame(award_winners[\"intro\"]).apply(lambda x: x[0].split(\"\\n\"), axis = 1).apply(lambda x: len(x))\n",
    "award_winners_intro[\"common_words\"] = pd.DataFrame(award_winners[\"intro\"]).apply(lambda x: FreqDist(x[0].split()).most_common(10), axis = 1).apply(lambda x: [i[0] for i in x]).apply(lambda x: \", \".join(x))\n",
    "award_winners_intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1264,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stopwords = stopwords.words(\"english\")\n",
    "award_winners_intro_remove_stopwords = pd.DataFrame(award_winners[\"intro\"]).apply(lambda x: \" \".join([word for word in word_tokenize(x[0]) if word not in (en_stopwords)]), axis = 1)\n",
    "award_winners_intro_remove_stopwords_and_punctuation = award_winners_intro_remove_stopwords.apply(lambda x: RegexpTokenizer(r'\\w+').tokenize(x)).apply(lambda x: \" \".join(x))\n",
    "award_winners_intro[\"common_words_after_preprocessing\"] = award_winners_intro_remove_stopwords_and_punctuation.apply(lambda x: FreqDist(x.split()).most_common(10)).apply(lambda x: [i[0] for i in x]).apply(lambda x: \", \".join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>winner_name</th>\n",
       "      <th>count_words</th>\n",
       "      <th>count_sentences</th>\n",
       "      <th>count_paragraphs</th>\n",
       "      <th>common_words</th>\n",
       "      <th>common_words_after_preprocessing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tim Berners-Lee</td>\n",
       "      <td>359</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>the, of, and, He, a, is, Web, as, World, Wide</td>\n",
       "      <td>Web, He, World, Wide, Berners, Lee, s, Compute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yoshua Bengio</td>\n",
       "      <td>91</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>and, the, of, for, Bengio, is, a, work, deep, ...</td>\n",
       "      <td>Bengio, work, deep, learning, Learning, Hinton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Geoffrey Hinton</td>\n",
       "      <td>181</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>the, and, of, for, in, Hinton, a, his, to, is</td>\n",
       "      <td>Hinton, computer, work, neural, networks, Goog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Donald Knuth</td>\n",
       "      <td>184</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>the, of, and, Knuth, computer, is, to, He, ana...</td>\n",
       "      <td>Knuth, computer, He, science, analysis, algori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Richard M. Karp</td>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>in, and, the, of, for, Karp, is, computer, the...</td>\n",
       "      <td>Karp, computer, theory, algorithms, Richard, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Robert Tarjan</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>and, is, the, of, Tarjan, at, Robert, Endre, (...</td>\n",
       "      <td>Tarjan, University, Robert, Endre, born, April...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vint Cerf</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>the, of, and, is, National, Medal, Vinton, Gra...</td>\n",
       "      <td>Internet, National, Medal, Vinton, Gray, Cerf,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Judea Pearl</td>\n",
       "      <td>156</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>the, and, of, for, is, on, Pearl, a, in, Judea</td>\n",
       "      <td>Pearl, Judea, American, computer, probabilisti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Herbert A. Simon</td>\n",
       "      <td>181</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>the, of, and, was, in, science,, to, political...</td>\n",
       "      <td>science, political, computer, He, Simon, 2001,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Marvin Minsky</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>and, of, Minsky, the, AI, Marvin, Lee, (August...</td>\n",
       "      <td>AI, Minsky, Marvin, Lee, August, 9, 1927, Janu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        winner_name  count_words  count_sentences  count_paragraphs  \\\n",
       "0   Tim Berners-Lee          359               17                 4   \n",
       "1     Yoshua Bengio           91                4                 2   \n",
       "2   Geoffrey Hinton          181                8                 3   \n",
       "3      Donald Knuth          184                8                 3   \n",
       "4   Richard M. Karp           92                3                 2   \n",
       "5     Robert Tarjan           62                3                 1   \n",
       "6         Vint Cerf           65                2                 1   \n",
       "7       Judea Pearl          156                5                 2   \n",
       "8  Herbert A. Simon          181                7                 2   \n",
       "9     Marvin Minsky           54                2                 2   \n",
       "\n",
       "                                        common_words  \\\n",
       "0      the, of, and, He, a, is, Web, as, World, Wide   \n",
       "1  and, the, of, for, Bengio, is, a, work, deep, ...   \n",
       "2      the, and, of, for, in, Hinton, a, his, to, is   \n",
       "3  the, of, and, Knuth, computer, is, to, He, ana...   \n",
       "4  in, and, the, of, for, Karp, is, computer, the...   \n",
       "5  and, is, the, of, Tarjan, at, Robert, Endre, (...   \n",
       "6  the, of, and, is, National, Medal, Vinton, Gra...   \n",
       "7     the, and, of, for, is, on, Pearl, a, in, Judea   \n",
       "8  the, of, and, was, in, science,, to, political...   \n",
       "9  and, of, Minsky, the, AI, Marvin, Lee, (August...   \n",
       "\n",
       "                    common_words_after_preprocessing  \n",
       "0  Web, He, World, Wide, Berners, Lee, s, Compute...  \n",
       "1  Bengio, work, deep, learning, Learning, Hinton...  \n",
       "2  Hinton, computer, work, neural, networks, Goog...  \n",
       "3  Knuth, computer, He, science, analysis, algori...  \n",
       "4  Karp, computer, theory, algorithms, Richard, M...  \n",
       "5  Tarjan, University, Robert, Endre, born, April...  \n",
       "6  Internet, National, Medal, Vinton, Gray, Cerf,...  \n",
       "7  Pearl, Judea, American, computer, probabilisti...  \n",
       "8  science, political, computer, He, Simon, 2001,...  \n",
       "9  AI, Minsky, Marvin, Lee, August, 9, 1927, Janu...  "
      ]
     },
     "execution_count": 1265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "award_winners_intro.iloc[0:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Sub-activity: Applying NLP operations on the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1266,
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_words = []\n",
    "for i in range(len(award_winners[\"intro\"])):\n",
    "    tokens = word_tokenize(award_winners[\"intro\"][i])\n",
    "    # Remove stopwords\n",
    "    award_winners[\"intro\"][i] = \" \".join([word for word in tokens if word not in en_stopwords])\n",
    "    # Remove punctuation\n",
    "    for token in RegexpTokenizer(r'\\w+').tokenize(award_winners[\"intro\"][i]): intro_words.append(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique words in intro_words is: 1757.\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of unique words in intro_words is: {}.\".format(len(FreqDist(intro_words).keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique words after stemming in intro_words is: 1441.\n"
     ]
    }
   ],
   "source": [
    "porter_stemmer = PorterStemmer()\n",
    "print(\"The number of unique words after stemming in intro_words is: {}.\".format(len(FreqDist([porter_stemmer.stem(word) for word in intro_words]).keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique words in intro_words is: 1757.\n",
      "The number of unique words after stemming in intro_words is: 1438.\n"
     ]
    }
   ],
   "source": [
    "snowball_stemmer = SnowballStemmer(\"english\")\n",
    "print(\"The number of unique words in intro_words is: {}.\".format(len(FreqDist(intro_words).keys())))\n",
    "print(\"The number of unique words after stemming in intro_words is: {}.\".format(len(FreqDist([snowball_stemmer.stem(word) for word in intro_words]).keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique words in intro_words is: 1757.\n",
      "The number of unique words after lemmatization in intro_words is: 1702.\n"
     ]
    }
   ],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "print(\"The number of unique words in intro_words is: {}.\".format(len(FreqDist(intro_words).keys())))\n",
    "print(\"The number of unique words after lemmatization in intro_words is: {}.\".format(len(FreqDist([wordnet_lemmatizer.lemmatize(word) for word in intro_words]).keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Finding synonyms and antonyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>winner_name</th>\n",
       "      <th>count_words</th>\n",
       "      <th>count_sentences</th>\n",
       "      <th>count_paragraphs</th>\n",
       "      <th>common_words</th>\n",
       "      <th>common_words_after_preprocessing</th>\n",
       "      <th>synonyms</th>\n",
       "      <th>antonyms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tim Berners-Lee</td>\n",
       "      <td>359</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>the, of, and, He, a, is, Web, as, World, Wide</td>\n",
       "      <td>Web, He, World, Wide, Berners, Lee, s, Compute...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yoshua Bengio</td>\n",
       "      <td>91</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>and, the, of, for, Bengio, is, a, work, deep, ...</td>\n",
       "      <td>Bengio, work, deep, learning, Learning, Hinton...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Geoffrey Hinton</td>\n",
       "      <td>181</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>the, and, of, for, in, Hinton, a, his, to, is</td>\n",
       "      <td>Hinton, computer, work, neural, networks, Goog...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Donald Knuth</td>\n",
       "      <td>184</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>the, of, and, Knuth, computer, is, to, He, ana...</td>\n",
       "      <td>Knuth, computer, He, science, analysis, algori...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Richard M. Karp</td>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>in, and, the, of, for, Karp, is, computer, the...</td>\n",
       "      <td>Karp, computer, theory, algorithms, Richard, M...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Fernando J. Corbató</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a, Fernando, José, \"Corby\", Corbató, (July, 1,...</td>\n",
       "      <td>July, Fernando, José, Corby, Corbató, 1, 1926,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Charles Bachman</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>his, Bachman, was, an, in, of, Charles, Willia...</td>\n",
       "      <td>Bachman, Charles, William, III, December, 11, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Butler Lampson</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Butler, W., Lampson,, ForMemRS,, (born, Decemb...</td>\n",
       "      <td>Butler, W, Lampson, ForMemRS, born, December, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Ole-Johan Dahl</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>of, Dahl, was, a, computer, the, and, Ole-Joha...</td>\n",
       "      <td>Dahl, computer, Ole, Johan, 12, October, 1931,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Charles P. Thacker</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>computer, the, Charles, Patrick, \"Chuck\", Thac...</td>\n",
       "      <td>computer, Charles, Patrick, Chuck, Thacker, Fe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            winner_name  count_words  count_sentences  count_paragraphs  \\\n",
       "0       Tim Berners-Lee          359               17                 4   \n",
       "1         Yoshua Bengio           91                4                 2   \n",
       "2       Geoffrey Hinton          181                8                 3   \n",
       "3          Donald Knuth          184                8                 3   \n",
       "4       Richard M. Karp           92                3                 2   \n",
       "..                  ...          ...              ...               ...   \n",
       "70  Fernando J. Corbató           28                1                 1   \n",
       "71      Charles Bachman           57                3                 1   \n",
       "72       Butler Lampson           27                1                 1   \n",
       "73       Ole-Johan Dahl           44                2                 1   \n",
       "74   Charles P. Thacker           35                2                 1   \n",
       "\n",
       "                                         common_words  \\\n",
       "0       the, of, and, He, a, is, Web, as, World, Wide   \n",
       "1   and, the, of, for, Bengio, is, a, work, deep, ...   \n",
       "2       the, and, of, for, in, Hinton, a, his, to, is   \n",
       "3   the, of, and, Knuth, computer, is, to, He, ana...   \n",
       "4   in, and, the, of, for, Karp, is, computer, the...   \n",
       "..                                                ...   \n",
       "70  a, Fernando, José, \"Corby\", Corbató, (July, 1,...   \n",
       "71  his, Bachman, was, an, in, of, Charles, Willia...   \n",
       "72  Butler, W., Lampson,, ForMemRS,, (born, Decemb...   \n",
       "73  of, Dahl, was, a, computer, the, and, Ole-Joha...   \n",
       "74  computer, the, Charles, Patrick, \"Chuck\", Thac...   \n",
       "\n",
       "                     common_words_after_preprocessing  synonyms  antonyms  \n",
       "0   Web, He, World, Wide, Berners, Lee, s, Compute...       NaN       NaN  \n",
       "1   Bengio, work, deep, learning, Learning, Hinton...       NaN       NaN  \n",
       "2   Hinton, computer, work, neural, networks, Goog...       NaN       NaN  \n",
       "3   Knuth, computer, He, science, analysis, algori...       NaN       NaN  \n",
       "4   Karp, computer, theory, algorithms, Richard, M...       NaN       NaN  \n",
       "..                                                ...       ...       ...  \n",
       "70  July, Fernando, José, Corby, Corbató, 1, 1926,...       NaN       NaN  \n",
       "71  Bachman, Charles, William, III, December, 11, ...       NaN       NaN  \n",
       "72  Butler, W, Lampson, ForMemRS, born, December, ...       NaN       NaN  \n",
       "73  Dahl, computer, Ole, Johan, 12, October, 1931,...       NaN       NaN  \n",
       "74  computer, Charles, Patrick, Chuck, Thacker, Fe...       NaN       NaN  \n",
       "\n",
       "[75 rows x 8 columns]"
      ]
     },
     "execution_count": 1271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "award_winners_intro = award_winners_intro.reindex(award_winners_intro.columns.to_list() + [\"synonyms\", \"antonyms\"], axis = 1)\n",
    "award_winners_intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonyms(words):\n",
    "    synonyms = []\n",
    "    for word in words:\n",
    "        for syn in wordnet.synsets(word):\n",
    "            for lemma in syn.lemmas():\n",
    "                synonyms.append(lemma.name())\n",
    "    return synonyms\n",
    "\n",
    "award_winners_intro[\"synonyms\"] = award_winners_intro[\"common_words_after_preprocessing\"].apply(lambda x: get_synonyms(word_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [web, web, entanglement, vane, web, network, w...\n",
       "1     [work, work, piece_of_work, employment, work, ...\n",
       "2     [computer, computing_machine, computing_device...\n",
       "3     [computer, computing_machine, computing_device...\n",
       "4     [computer, computing_machine, computing_device...\n",
       "                            ...                        \n",
       "70    [July, one, 1, I, ace, single, unity, one, 1, ...\n",
       "71    [Charles, Charles_IX, Charles, Charles_VII, Ch...\n",
       "72    [butler, pantryman, Butler, Samuel_Butler, But...\n",
       "73    [pigeon_pea, pigeon-pea_plant, cajan_pea, catj...\n",
       "74    [computer, computing_machine, computing_device...\n",
       "Name: synonyms, Length: 75, dtype: object"
      ]
     },
     "execution_count": 1273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "award_winners_intro[\"synonyms\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_antonyms(words):\n",
    "    antonyms = []\n",
    "    for word in words:\n",
    "        for syn in wordnet.synsets(word):\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.antonyms():\n",
    "                    antonyms.append(lemma.antonyms()[0].name())\n",
    "    return antonyms\n",
    "\n",
    "award_winners_intro[\"antonyms\"] = award_winners_intro[\"common_words_after_preprocessing\"].apply(lambda x: get_antonyms(word_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        [narrow, narrow, windward]\n",
       "1     [idle, malfunction, shallow, shallow, unborn]\n",
       "2             [idle, malfunction, shallow, shallow]\n",
       "3                                       [synthesis]\n",
       "4                                          [unborn]\n",
       "                          ...                      \n",
       "70                                               []\n",
       "71                                               []\n",
       "72                                         [unborn]\n",
       "73                                               []\n",
       "74                                      [keep_down]\n",
       "Name: antonyms, Length: 75, dtype: object"
      ]
     },
     "execution_count": 1275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "award_winners_intro[\"antonyms\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>winner_name</th>\n",
       "      <th>count_words</th>\n",
       "      <th>count_sentences</th>\n",
       "      <th>count_paragraphs</th>\n",
       "      <th>common_words</th>\n",
       "      <th>common_words_after_preprocessing</th>\n",
       "      <th>synonyms</th>\n",
       "      <th>antonyms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tim Berners-Lee</td>\n",
       "      <td>359</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>the, of, and, He, a, is, Web, as, World, Wide</td>\n",
       "      <td>Web, He, World, Wide, Berners, Lee, s, Compute...</td>\n",
       "      <td>[web, web, entanglement, vane, web, network, w...</td>\n",
       "      <td>[narrow, narrow, windward]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yoshua Bengio</td>\n",
       "      <td>91</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>and, the, of, for, Bengio, is, a, work, deep, ...</td>\n",
       "      <td>Bengio, work, deep, learning, Learning, Hinton...</td>\n",
       "      <td>[work, work, piece_of_work, employment, work, ...</td>\n",
       "      <td>[idle, malfunction, shallow, shallow, unborn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Geoffrey Hinton</td>\n",
       "      <td>181</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>the, and, of, for, in, Hinton, a, his, to, is</td>\n",
       "      <td>Hinton, computer, work, neural, networks, Goog...</td>\n",
       "      <td>[computer, computing_machine, computing_device...</td>\n",
       "      <td>[idle, malfunction, shallow, shallow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Donald Knuth</td>\n",
       "      <td>184</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>the, of, and, Knuth, computer, is, to, He, ana...</td>\n",
       "      <td>Knuth, computer, He, science, analysis, algori...</td>\n",
       "      <td>[computer, computing_machine, computing_device...</td>\n",
       "      <td>[synthesis]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Richard M. Karp</td>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>in, and, the, of, for, Karp, is, computer, the...</td>\n",
       "      <td>Karp, computer, theory, algorithms, Richard, M...</td>\n",
       "      <td>[computer, computing_machine, computing_device...</td>\n",
       "      <td>[unborn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Robert Tarjan</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>and, is, the, of, Tarjan, at, Robert, Endre, (...</td>\n",
       "      <td>Tarjan, University, Robert, Endre, born, April...</td>\n",
       "      <td>[university, university, university, Robert, H...</td>\n",
       "      <td>[unborn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vint Cerf</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>the, of, and, is, National, Medal, Vinton, Gra...</td>\n",
       "      <td>Internet, National, Medal, Vinton, Gray, Cerf,...</td>\n",
       "      <td>[internet, net, cyberspace, national, subject,...</td>\n",
       "      <td>[international, local, unborn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Judea Pearl</td>\n",
       "      <td>156</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>the, and, of, for, is, on, Pearl, a, in, Judea</td>\n",
       "      <td>Pearl, Judea, American, computer, probabilisti...</td>\n",
       "      <td>[pearl, bone, ivory, pearl, off-white, drop, b...</td>\n",
       "      <td>[natural, stupidity, devolution, nondevelopment]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Herbert A. Simon</td>\n",
       "      <td>181</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>the, of, and, was, in, science,, to, political...</td>\n",
       "      <td>science, political, computer, He, Simon, 2001,...</td>\n",
       "      <td>[science, scientific_discipline, skill, scienc...</td>\n",
       "      <td>[nonpolitical]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Marvin Minsky</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>and, of, Minsky, the, AI, Marvin, Lee, (August...</td>\n",
       "      <td>AI, Minsky, Marvin, Lee, August, 9, 1927, Janu...</td>\n",
       "      <td>[Army_Intelligence, AI, artificial_intelligenc...</td>\n",
       "      <td>[windward]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        winner_name  count_words  count_sentences  count_paragraphs  \\\n",
       "0   Tim Berners-Lee          359               17                 4   \n",
       "1     Yoshua Bengio           91                4                 2   \n",
       "2   Geoffrey Hinton          181                8                 3   \n",
       "3      Donald Knuth          184                8                 3   \n",
       "4   Richard M. Karp           92                3                 2   \n",
       "5     Robert Tarjan           62                3                 1   \n",
       "6         Vint Cerf           65                2                 1   \n",
       "7       Judea Pearl          156                5                 2   \n",
       "8  Herbert A. Simon          181                7                 2   \n",
       "9     Marvin Minsky           54                2                 2   \n",
       "\n",
       "                                        common_words  \\\n",
       "0      the, of, and, He, a, is, Web, as, World, Wide   \n",
       "1  and, the, of, for, Bengio, is, a, work, deep, ...   \n",
       "2      the, and, of, for, in, Hinton, a, his, to, is   \n",
       "3  the, of, and, Knuth, computer, is, to, He, ana...   \n",
       "4  in, and, the, of, for, Karp, is, computer, the...   \n",
       "5  and, is, the, of, Tarjan, at, Robert, Endre, (...   \n",
       "6  the, of, and, is, National, Medal, Vinton, Gra...   \n",
       "7     the, and, of, for, is, on, Pearl, a, in, Judea   \n",
       "8  the, of, and, was, in, science,, to, political...   \n",
       "9  and, of, Minsky, the, AI, Marvin, Lee, (August...   \n",
       "\n",
       "                    common_words_after_preprocessing  \\\n",
       "0  Web, He, World, Wide, Berners, Lee, s, Compute...   \n",
       "1  Bengio, work, deep, learning, Learning, Hinton...   \n",
       "2  Hinton, computer, work, neural, networks, Goog...   \n",
       "3  Knuth, computer, He, science, analysis, algori...   \n",
       "4  Karp, computer, theory, algorithms, Richard, M...   \n",
       "5  Tarjan, University, Robert, Endre, born, April...   \n",
       "6  Internet, National, Medal, Vinton, Gray, Cerf,...   \n",
       "7  Pearl, Judea, American, computer, probabilisti...   \n",
       "8  science, political, computer, He, Simon, 2001,...   \n",
       "9  AI, Minsky, Marvin, Lee, August, 9, 1927, Janu...   \n",
       "\n",
       "                                            synonyms  \\\n",
       "0  [web, web, entanglement, vane, web, network, w...   \n",
       "1  [work, work, piece_of_work, employment, work, ...   \n",
       "2  [computer, computing_machine, computing_device...   \n",
       "3  [computer, computing_machine, computing_device...   \n",
       "4  [computer, computing_machine, computing_device...   \n",
       "5  [university, university, university, Robert, H...   \n",
       "6  [internet, net, cyberspace, national, subject,...   \n",
       "7  [pearl, bone, ivory, pearl, off-white, drop, b...   \n",
       "8  [science, scientific_discipline, skill, scienc...   \n",
       "9  [Army_Intelligence, AI, artificial_intelligenc...   \n",
       "\n",
       "                                           antonyms  \n",
       "0                        [narrow, narrow, windward]  \n",
       "1     [idle, malfunction, shallow, shallow, unborn]  \n",
       "2             [idle, malfunction, shallow, shallow]  \n",
       "3                                       [synthesis]  \n",
       "4                                          [unborn]  \n",
       "5                                          [unborn]  \n",
       "6                    [international, local, unborn]  \n",
       "7  [natural, stupidity, devolution, nondevelopment]  \n",
       "8                                    [nonpolitical]  \n",
       "9                                        [windward]  "
      ]
     },
     "execution_count": 1276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "award_winners_intro.iloc[0:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4 Bigrams and trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1277,
   "metadata": {},
   "outputs": [],
   "source": [
    "award_winners_intro_tokenized = []\n",
    "for i in range(len(award_winners[\"intro\"])):\n",
    "    tokens = word_tokenize(award_winners[\"intro\"][i])\n",
    "    # Remove stopwords\n",
    "    award_winners[\"intro\"][i] = \" \".join([word for word in tokens if word not in en_stopwords])\n",
    "    # Remove punctuation\n",
    "    for token in RegexpTokenizer(r'\\w+').tokenize(award_winners[\"intro\"][i]): award_winners_intro_tokenized.append(token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigrams_frequency(words):\n",
    "    bigrams = ngrams(words, 2)\n",
    "    return FreqDist(bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1279,
   "metadata": {},
   "outputs": [],
   "source": [
    "winners_bigrams = get_bigrams_frequency(award_winners_intro_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('computer', 'scientist'), 58), (('Turing', 'Award'), 56), (('American', 'computer'), 33), (('computer', 'science'), 25), (('Computer', 'Science'), 24), (('He', 'also'), 13), (('programming', 'language'), 13), (('best', 'known'), 11), (('He', 'received'), 11), (('National', 'Academy'), 10), (('artificial', 'intelligence'), 10), (('programming', 'languages'), 10), (('received', 'Turing'), 9), (('Academy', 'Engineering'), 8), (('Carnegie', 'Mellon'), 8)]\n"
     ]
    }
   ],
   "source": [
    "print(winners_bigrams.most_common(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Sub-section: Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Barplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
