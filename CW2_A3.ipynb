{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Sub-activity: Loading and pre-processing of text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "\n",
    "WIKIDATA_API_ENDPOINT = \"https://www.wikidata.org/w/api.php\"\n",
    "\n",
    "PARAMS = {\n",
    "        \"format\":\"json\",\n",
    "        \"formatversion\": \"2\",\n",
    "        \"sitefilter\": \"enwiki\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_turing_award_recipients():\n",
    "    \n",
    "    wikidata_ID_params = {\n",
    "    \"action\":\"query\",\n",
    "    \"format\":\"json\",\n",
    "    \"list\":\"search\",\n",
    "    \"srprop\":\"sectiontitle\",\n",
    "    \"srsearch\": \"haswbstatement:P166=Q185667\",\n",
    "    \"formatversion\": \"2\",\n",
    "    \"srlimit\":100\n",
    "    }\n",
    "\n",
    "    wikidata_ID_response = requests.get(WIKIDATA_API_ENDPOINT, params = wikidata_ID_params)\n",
    "    wikidata_ID_data = wikidata_ID_response.json()    \n",
    "    wikidata_IDs = [entity_ID[\"title\"] for entity_ID in wikidata_ID_data[\"query\"][\"search\"]]\n",
    "\n",
    "    return wikidata_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidata_IDs = get_turing_award_recipients()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q80', 'Q3572699', 'Q92894', 'Q17457', 'Q92612', 'Q92638', 'Q92743', 'Q92824', 'Q181529', 'Q204815', 'Q578036', 'Q92794', 'Q92739', 'Q49823', 'Q92602', 'Q3571662', 'Q92626', 'Q92758', 'Q16080922', 'Q62870', 'Q8556', 'Q92604', 'Q357965', 'Q11609', 'Q92609', 'Q439245', 'Q92670', 'Q92819', 'Q92851', 'Q92613', 'Q62874', 'Q92854', 'Q92628', 'Q7143512', 'Q62861', 'Q320624', 'Q45575', 'Q1107006', 'Q92614', 'Q62888', 'Q93080', 'Q476466', 'Q92820', 'Q92649', 'Q62898', 'Q92641', 'Q92742', 'Q93154', 'Q62843', 'Q92643', 'Q92823', 'Q462089', 'Q62866', 'Q92629', 'Q92618', 'Q92822', 'Q92596', 'Q92746', 'Q918650', 'Q62857', 'Q92619', 'Q92821', 'Q62877', 'Q92782', 'Q92632', 'Q93161', 'Q92744', 'Q92606', 'Q92781', 'Q9602', 'Q92625', 'Q62894', 'Q92644', 'Q92745', 'Q92828']\n"
     ]
    }
   ],
   "source": [
    "print(wikidata_IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wikipedia_content(wikidata_ID):\n",
    "    wikipedia_API_endpoint = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "    WIKIDATA_GET_CONTENT_PARAMS = {\n",
    "        \"action\":\"wbgetentities\",\n",
    "        \"format\":\"json\",\n",
    "        \"ids\": wikidata_ID,\n",
    "        \"formatversion\": \"2\",\n",
    "        \"sitefilter\": \"enwiki\"\n",
    "    }\n",
    "    \n",
    "    wikidata_response = requests.get(WIKIDATA_API_ENDPOINT, params = WIKIDATA_GET_CONTENT_PARAMS)\n",
    "    wikidata_response_data = wikidata_response.json()\n",
    "\n",
    "    # To extract content from the wikipidia page, we have to use titles gained the wikidata IDs, since the titles of wikipedia pages are unique.\n",
    "    wikidata_title = wikidata_response_data[\"entities\"][wikidata_ID][\"sitelinks\"][\"enwiki\"][\"title\"]\n",
    "\n",
    "    wikipedia_content_params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"prop\": \"extracts\",\n",
    "        \"titles\": wikidata_title,\n",
    "        \"formatversion\": \"2\",\n",
    "        \"exsectionformat\": \"wiki\",\n",
    "    }\n",
    "\n",
    "    wikipedia_content_response = requests.get(wikipedia_API_endpoint, params = wikipedia_content_params)\n",
    "    wikipedia_content_data = wikipedia_content_response.json()\n",
    "    wikipedia_content = wikipedia_content_data[\"query\"][\"pages\"][0][\"extract\"]\n",
    "    return wikipedia_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q92743 = get_wikipedia_content(\"Q92743\")\n",
    "# Q80 = get_wikipedia_content(\"Q80\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_paragraphs(content):\n",
    "#     cleaned_content = re.sub(r\"\\\\|\\n\",\"\", content)\n",
    "#     content_with_p_tag = re.sub(r\"<\\/?(?!p)\\w*\\b[^>]*>\", \"\", cleaned_content.split(\"<h2>\")[0])\n",
    "#     paragraphs = re.findall(r'<p>(.+?)</p>', content_with_p_tag)\n",
    "#     paragraphs = \" \\n\".join(paragraphs)\n",
    "#     return paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for wikidata_ID in wikidata_IDs:\n",
    "#     content = get_wikipedia_content(wikidata_ID)\n",
    "#     paragraphs = get_paragraphs(content)\n",
    "#     print(paragraphs)\n",
    "#     print(\"lol\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_award_winners_info(wikidata_ID):\n",
    "    \n",
    "    wikidata_params = {\n",
    "        \"action\":\"wbgetentities\",\n",
    "        \"format\":\"json\",\n",
    "        \"ids\": wikidata_ID,\n",
    "        \"props\": \"claims|sitelinks\",\n",
    "        \"formatversion\": \"2\",\n",
    "        \"languages\": \"en\",\n",
    "        \"sitefilter\": \"enwiki\"\n",
    "    }\n",
    "\n",
    "    wikidata_title_response = requests.get(WIKIDATA_API_ENDPOINT, params = wikidata_params)\n",
    "    wikidata_title_data = wikidata_title_response.json()\n",
    "\n",
    "    # Extract name\n",
    "    try:\n",
    "        wikidata_name = wikidata_title_data[\"entities\"][wikidata_ID][\"sitelinks\"][\"enwiki\"][\"title\"]\n",
    "    except KeyError:\n",
    "        wikidata_name = None\n",
    "\n",
    "    # Extract intro from wikipedia page\n",
    "    try:\n",
    "        wikipedia_content = get_wikipedia_content(wikidata_ID)\n",
    "        cleaned_content = re.sub(r\"\\\\|\\n\",\"\", wikipedia_content)\n",
    "        content_with_p_tag = re.sub(r\"<\\/?(?!p)\\w*\\b[^>]*>\", \"\", cleaned_content.split(\"<h2>\")[0])\n",
    "        paragraphs = re.findall(r'<p>(.+?)</p>', content_with_p_tag)\n",
    "        wikipedia_intro = \" \\n\".join(paragraphs)\n",
    "\n",
    "    except KeyError:\n",
    "        wikipedia_intro = None\n",
    "    \n",
    "    # Extract gender ID to get gender from \"sex or gender (P21)\"\n",
    "    try:\n",
    "        wikidata_gender_id = wikidata_title_data[\"entities\"][wikidata_ID][\"claims\"][\"P21\"][0][\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"]\n",
    "    except KeyError:\n",
    "        wikidata_gender_id = None\n",
    "        \n",
    "    # Get birth date from \"date of birth (P569)\"\n",
    "    try:\n",
    "        wikidata_birth_date = wikidata_title_data[\"entities\"][wikidata_ID][\"claims\"][\"P569\"][0][\"mainsnak\"][\"datavalue\"][\"value\"][\"time\"].split(\"T\")[0].split(\"+\")[1]\n",
    "    except KeyError:\n",
    "        wikidata_birth_date = None\n",
    "\n",
    "    # Extract birth place ID to get birth place from \"place of birth (P19)\"\n",
    "    try:\n",
    "        wikidata_birth_place = wikidata_title_data[\"entities\"][wikidata_ID][\"claims\"][\"P19\"][0][\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"]\n",
    "    except KeyError:\n",
    "        wikidata_birth_place = None\n",
    "\n",
    "    # Extract employer ID to get employer from \"employer (P108)\"\n",
    "    # employer ID is inside of \"mainsnak\" key\n",
    "    try:\n",
    "        wikidata_employer_mainsnaks = wikidata_title_data[\"entities\"][wikidata_ID][\"claims\"][\"P108\"]\n",
    "    except KeyError:\n",
    "        wikidata_employers_IDs = None\n",
    "    else:\n",
    "        wikidata_employers_IDs = [wikidata_employer_ID[\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"] for wikidata_employer_ID in wikidata_employer_mainsnaks]\n",
    "\n",
    "    # Extract educated at ID to get educated at from \"educated at (P69)\"\n",
    "    # educated at ID is inside of \"mainsnak\" key\n",
    "    try:\n",
    "        wikidata_educated_at_mainsnaks = wikidata_title_data[\"entities\"][wikidata_ID][\"claims\"][\"P69\"]\n",
    "    except KeyError:\n",
    "        wikidata_educated_at_IDs = None\n",
    "    else:\n",
    "        wikidata_educated_at_IDs = [wikidata_educated_at_ID[\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"] for wikidata_educated_at_ID in wikidata_educated_at_mainsnaks]\n",
    "\n",
    "    entity_info_request_IDs = [wikidata_gender_id, wikidata_birth_place, \"|\".join(wikidata_employers_IDs), \"|\".join(wikidata_educated_at_IDs)]\n",
    "    \n",
    "    entity_info = [wikidata_name, wikipedia_intro, wikidata_birth_date]\n",
    "    for entity_info_request_ID in entity_info_request_IDs:\n",
    "\n",
    "        wikidata_params_2 = {\n",
    "            \"action\":\"wbgetentities\",\n",
    "            \"format\":\"json\",\n",
    "            \"ids\": entity_info_request_ID,\n",
    "            \"props\": \"labels\",\n",
    "            \"formatversion\": \"2\",\n",
    "            \"languages\": \"en\",\n",
    "            \"sitefilter\": \"enwiki\"\n",
    "        }\n",
    "        \n",
    "        entity_values = []\n",
    "        entity_info_response = requests.get(WIKIDATA_API_ENDPOINT, params = wikidata_params_2)\n",
    "        entity_info_data = entity_info_response.json()\n",
    "\n",
    "        try:\n",
    "            entity_IDs = entity_info_request_ID.split(\"|\")\n",
    "        except AttributeError:\n",
    "            entity_IDs = []\n",
    "        \n",
    "        for entity_ID in entity_IDs:\n",
    "            try:\n",
    "                entity_value = entity_info_data[\"entities\"][entity_ID][\"labels\"][\"en\"][\"value\"]\n",
    "                entity_values.append(entity_value)\n",
    "            except KeyError:\n",
    "                entity_values.append(None)\n",
    "        \n",
    "        # print(entity_values)\n",
    "        entity_info.append(entity_values)\n",
    "    \n",
    "    return entity_info[0], entity_info[1], entity_info[2], entity_info[3], entity_info[4], entity_info[5], entity_info[6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/congrendai/Desktop/King's/Computer Programming for Data Scientists/CW2/CW2_A3.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/congrendai/Desktop/King%27s/Computer%20Programming%20for%20Data%20Scientists/CW2/CW2_A3.ipynb#Z1125sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m award_winners \u001b[39m=\u001b[39m {\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/congrendai/Desktop/King%27s/Computer%20Programming%20for%20Data%20Scientists/CW2/CW2_A3.ipynb#Z1125sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: [],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/congrendai/Desktop/King%27s/Computer%20Programming%20for%20Data%20Scientists/CW2/CW2_A3.ipynb#Z1125sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mintro\u001b[39m\u001b[39m\"\u001b[39m: [],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/congrendai/Desktop/King%27s/Computer%20Programming%20for%20Data%20Scientists/CW2/CW2_A3.ipynb#Z1125sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39meducated_at\u001b[39m\u001b[39m\"\u001b[39m: []\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/congrendai/Desktop/King%27s/Computer%20Programming%20for%20Data%20Scientists/CW2/CW2_A3.ipynb#Z1125sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m }\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/congrendai/Desktop/King%27s/Computer%20Programming%20for%20Data%20Scientists/CW2/CW2_A3.ipynb#Z1125sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m wikidata_ID \u001b[39min\u001b[39;00m wikidata_IDs:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/congrendai/Desktop/King%27s/Computer%20Programming%20for%20Data%20Scientists/CW2/CW2_A3.ipynb#Z1125sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     wikidata_name, wikipedia_intro, wikidata_birth_date, wikidata_gender, wikidata_birth_place, wikidata_employer, wikidata_educated_at \u001b[39m=\u001b[39m get_award_winners_info(wikidata_ID)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/congrendai/Desktop/King%27s/Computer%20Programming%20for%20Data%20Scientists/CW2/CW2_A3.ipynb#Z1125sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     award_winners[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mappend(wikidata_name)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/congrendai/Desktop/King%27s/Computer%20Programming%20for%20Data%20Scientists/CW2/CW2_A3.ipynb#Z1125sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     award_winners[\u001b[39m\"\u001b[39m\u001b[39mintro\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mappend(wikipedia_intro)\n",
      "\u001b[1;32m/Users/congrendai/Desktop/King's/Computer Programming for Data Scientists/CW2/CW2_A3.ipynb Cell 17\u001b[0m in \u001b[0;36mget_award_winners_info\u001b[0;34m(wikidata_ID)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/congrendai/Desktop/King%27s/Computer%20Programming%20for%20Data%20Scientists/CW2/CW2_A3.ipynb#Z1125sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Extract intro from wikipedia page\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/congrendai/Desktop/King%27s/Computer%20Programming%20for%20Data%20Scientists/CW2/CW2_A3.ipynb#Z1125sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/congrendai/Desktop/King%27s/Computer%20Programming%20for%20Data%20Scientists/CW2/CW2_A3.ipynb#Z1125sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     wikipedia_content \u001b[39m=\u001b[39m get_wikipedia_content(wikidata_ID)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/congrendai/Desktop/King%27s/Computer%20Programming%20for%20Data%20Scientists/CW2/CW2_A3.ipynb#Z1125sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     cleaned_content \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m|\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mn\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, wikipedia_content)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/congrendai/Desktop/King%27s/Computer%20Programming%20for%20Data%20Scientists/CW2/CW2_A3.ipynb#Z1125sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     content_with_p_tag \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m<\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m/?(?!p)\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw*\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mb[^>]*>\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, cleaned_content\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m<h2>\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m])\n",
      "\u001b[1;32m/Users/congrendai/Desktop/King's/Computer Programming for Data Scientists/CW2/CW2_A3.ipynb Cell 17\u001b[0m in \u001b[0;36mget_wikipedia_content\u001b[0;34m(wikidata_ID)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/congrendai/Desktop/King%27s/Computer%20Programming%20for%20Data%20Scientists/CW2/CW2_A3.ipynb#Z1125sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m wikipedia_API_endpoint \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps://en.wikipedia.org/w/api.php\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/congrendai/Desktop/King%27s/Computer%20Programming%20for%20Data%20Scientists/CW2/CW2_A3.ipynb#Z1125sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m WIKIDATA_GET_CONTENT_PARAMS \u001b[39m=\u001b[39m {\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/congrendai/Desktop/King%27s/Computer%20Programming%20for%20Data%20Scientists/CW2/CW2_A3.ipynb#Z1125sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39maction\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39mwbgetentities\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/congrendai/Desktop/King%27s/Computer%20Programming%20for%20Data%20Scientists/CW2/CW2_A3.ipynb#Z1125sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39mjson\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/congrendai/Desktop/King%27s/Computer%20Programming%20for%20Data%20Scientists/CW2/CW2_A3.ipynb#Z1125sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msitefilter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39menwiki\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/congrendai/Desktop/King%27s/Computer%20Programming%20for%20Data%20Scientists/CW2/CW2_A3.ipynb#Z1125sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m }\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/congrendai/Desktop/King%27s/Computer%20Programming%20for%20Data%20Scientists/CW2/CW2_A3.ipynb#Z1125sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m wikidata_response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(WIKIDATA_API_ENDPOINT, params \u001b[39m=\u001b[39;49m WIKIDATA_GET_CONTENT_PARAMS)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/congrendai/Desktop/King%27s/Computer%20Programming%20for%20Data%20Scientists/CW2/CW2_A3.ipynb#Z1125sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m wikidata_response_data \u001b[39m=\u001b[39m wikidata_response\u001b[39m.\u001b[39mjson()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/congrendai/Desktop/King%27s/Computer%20Programming%20for%20Data%20Scientists/CW2/CW2_A3.ipynb#Z1125sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# To extract content from the wikipidia page, we have to use titles gained the wikidata IDs, since the titles of wikipedia pages are unique.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py:745\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n\u001b[0;32m--> 745\u001b[0m     r\u001b[39m.\u001b[39;49mcontent\n\u001b[1;32m    747\u001b[0m \u001b[39mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/requests/models.py:899\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    898\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 899\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter_content(CONTENT_CHUNK_SIZE)) \u001b[39mor\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    901\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content_consumed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    902\u001b[0m \u001b[39m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \u001b[39m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/urllib3/response.py:623\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    608\u001b[0m \u001b[39mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \u001b[39m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[39m    'content-encoding' header.\u001b[39;00m\n\u001b[1;32m    621\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunked \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupports_chunked_reads():\n\u001b[0;32m--> 623\u001b[0m     \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_chunked(amt, decode_content\u001b[39m=\u001b[39mdecode_content):\n\u001b[1;32m    624\u001b[0m         \u001b[39myield\u001b[39;00m line\n\u001b[1;32m    625\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/urllib3/response.py:815\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    812\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    814\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 815\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_chunk_length()\n\u001b[1;32m    816\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    817\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/urllib3/response.py:745\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    744\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 745\u001b[0m line \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline()\n\u001b[1;32m    746\u001b[0m line \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39msplit(\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m;\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    747\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    705\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/ssl.py:1242\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1238\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1239\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1240\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1241\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1242\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1243\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1244\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/ssl.py:1100\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1099\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1100\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1101\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1102\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "award_winners = {\n",
    "    \"name\": [],\n",
    "    \"intro\": [],\n",
    "    \"birth_date\": [],\n",
    "    \"gender\": [],\n",
    "    \"birth_place\": [],\n",
    "    \"employer\": [],\n",
    "    \"educated_at\": []\n",
    "}\n",
    "\n",
    "for wikidata_ID in wikidata_IDs:\n",
    "    wikidata_name, wikipedia_intro, wikidata_birth_date, wikidata_gender, wikidata_birth_place, wikidata_employer, wikidata_educated_at = get_award_winners_info(wikidata_ID)\n",
    "    award_winners[\"name\"].append(wikidata_name)\n",
    "    award_winners[\"intro\"].append(wikipedia_intro)\n",
    "    award_winners[\"birth_date\"].append(wikidata_birth_date)\n",
    "    award_winners[\"gender\"].append(wikidata_gender)\n",
    "    award_winners[\"birth_place\"].append(wikidata_birth_place)\n",
    "    award_winners[\"employer\"].append(wikidata_employer)\n",
    "    award_winners[\"educated_at\"].append(wikidata_educated_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>intro</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>gender</th>\n",
       "      <th>birth_place</th>\n",
       "      <th>employer</th>\n",
       "      <th>educated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tim Berners-Lee</td>\n",
       "      <td>Sir Timothy John Berners-Lee  (born 8 June 195...</td>\n",
       "      <td>1955-06-08</td>\n",
       "      <td>[male]</td>\n",
       "      <td>[London]</td>\n",
       "      <td>[World Wide Web Consortium, School of Electron...</td>\n",
       "      <td>[The Queen's College, Emanuel School]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yoshua Bengio</td>\n",
       "      <td>Yoshua Bengio  (born March 5, 1964) is a Canad...</td>\n",
       "      <td>1964-03-05</td>\n",
       "      <td>[male]</td>\n",
       "      <td>[Paris]</td>\n",
       "      <td>[Université de Montréal]</td>\n",
       "      <td>[McGill University, McGill University, McGill ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Geoffrey Hinton</td>\n",
       "      <td>Geoffrey Everest Hinton  (born 6 December 1947...</td>\n",
       "      <td>1947-12-06</td>\n",
       "      <td>[male]</td>\n",
       "      <td>[Wimbledon]</td>\n",
       "      <td>[University of Toronto, Google, Carnegie Mello...</td>\n",
       "      <td>[University of Edinburgh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Donald Knuth</td>\n",
       "      <td>Donald Ervin Knuth ( kə-NOOTH; born January 10...</td>\n",
       "      <td>1938-01-10</td>\n",
       "      <td>[male]</td>\n",
       "      <td>[Milwaukee]</td>\n",
       "      <td>[Stanford University, Burroughs Corporation, I...</td>\n",
       "      <td>[Case Western Reserve University, California I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Richard M. Karp</td>\n",
       "      <td>Richard Manning Karp (born January 3, 1935) is...</td>\n",
       "      <td>1935-01-03</td>\n",
       "      <td>[male]</td>\n",
       "      <td>[Boston]</td>\n",
       "      <td>[University of California, Berkeley, Universit...</td>\n",
       "      <td>[Harvard University, Harvard School of Enginee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Fernando J. Corbató</td>\n",
       "      <td>Fernando José \"Corby\" Corbató (July 1, 1926 – ...</td>\n",
       "      <td>1926-07-01</td>\n",
       "      <td>[male]</td>\n",
       "      <td>[Oakland]</td>\n",
       "      <td>[Massachusetts Institute of Technology]</td>\n",
       "      <td>[California Institute of Technology, Massachus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Charles Bachman</td>\n",
       "      <td>Charles William Bachman III (December 11, 1924...</td>\n",
       "      <td>1924-12-11</td>\n",
       "      <td>[male]</td>\n",
       "      <td>[Manhattan]</td>\n",
       "      <td>[Dow Chemical Company, General Electric, Honey...</td>\n",
       "      <td>[Michigan State University, University of Penn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Butler Lampson</td>\n",
       "      <td>Butler W. Lampson, ForMemRS, (born December 23...</td>\n",
       "      <td>1943-12-23</td>\n",
       "      <td>[male]</td>\n",
       "      <td>[Washington, D.C.]</td>\n",
       "      <td>[PARC, Massachusetts Institute of Technology, ...</td>\n",
       "      <td>[Harvard University, University of California,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Ole-Johan Dahl</td>\n",
       "      <td>Ole-Johan Dahl (12 October 1931 – 29 June 2002...</td>\n",
       "      <td>1931-10-12</td>\n",
       "      <td>[male]</td>\n",
       "      <td>[Mandal]</td>\n",
       "      <td>[University of Oslo]</td>\n",
       "      <td>[University of Oslo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Charles P. Thacker</td>\n",
       "      <td>Charles Patrick \"Chuck\" Thacker (February 26, ...</td>\n",
       "      <td>1943-02-26</td>\n",
       "      <td>[male]</td>\n",
       "      <td>[Pasadena]</td>\n",
       "      <td>[PARC, Digital Equipment Corporation]</td>\n",
       "      <td>[University of California, Berkeley]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name                                              intro  \\\n",
       "0       Tim Berners-Lee  Sir Timothy John Berners-Lee  (born 8 June 195...   \n",
       "1         Yoshua Bengio  Yoshua Bengio  (born March 5, 1964) is a Canad...   \n",
       "2       Geoffrey Hinton  Geoffrey Everest Hinton  (born 6 December 1947...   \n",
       "3          Donald Knuth  Donald Ervin Knuth ( kə-NOOTH; born January 10...   \n",
       "4       Richard M. Karp  Richard Manning Karp (born January 3, 1935) is...   \n",
       "..                  ...                                                ...   \n",
       "70  Fernando J. Corbató  Fernando José \"Corby\" Corbató (July 1, 1926 – ...   \n",
       "71      Charles Bachman  Charles William Bachman III (December 11, 1924...   \n",
       "72       Butler Lampson  Butler W. Lampson, ForMemRS, (born December 23...   \n",
       "73       Ole-Johan Dahl  Ole-Johan Dahl (12 October 1931 – 29 June 2002...   \n",
       "74   Charles P. Thacker  Charles Patrick \"Chuck\" Thacker (February 26, ...   \n",
       "\n",
       "    birth_date  gender         birth_place  \\\n",
       "0   1955-06-08  [male]            [London]   \n",
       "1   1964-03-05  [male]             [Paris]   \n",
       "2   1947-12-06  [male]         [Wimbledon]   \n",
       "3   1938-01-10  [male]         [Milwaukee]   \n",
       "4   1935-01-03  [male]            [Boston]   \n",
       "..         ...     ...                 ...   \n",
       "70  1926-07-01  [male]           [Oakland]   \n",
       "71  1924-12-11  [male]         [Manhattan]   \n",
       "72  1943-12-23  [male]  [Washington, D.C.]   \n",
       "73  1931-10-12  [male]            [Mandal]   \n",
       "74  1943-02-26  [male]          [Pasadena]   \n",
       "\n",
       "                                             employer  \\\n",
       "0   [World Wide Web Consortium, School of Electron...   \n",
       "1                            [Université de Montréal]   \n",
       "2   [University of Toronto, Google, Carnegie Mello...   \n",
       "3   [Stanford University, Burroughs Corporation, I...   \n",
       "4   [University of California, Berkeley, Universit...   \n",
       "..                                                ...   \n",
       "70            [Massachusetts Institute of Technology]   \n",
       "71  [Dow Chemical Company, General Electric, Honey...   \n",
       "72  [PARC, Massachusetts Institute of Technology, ...   \n",
       "73                               [University of Oslo]   \n",
       "74              [PARC, Digital Equipment Corporation]   \n",
       "\n",
       "                                          educated_at  \n",
       "0               [The Queen's College, Emanuel School]  \n",
       "1   [McGill University, McGill University, McGill ...  \n",
       "2                           [University of Edinburgh]  \n",
       "3   [Case Western Reserve University, California I...  \n",
       "4   [Harvard University, Harvard School of Enginee...  \n",
       "..                                                ...  \n",
       "70  [California Institute of Technology, Massachus...  \n",
       "71  [Michigan State University, University of Penn...  \n",
       "72  [Harvard University, University of California,...  \n",
       "73                               [University of Oslo]  \n",
       "74               [University of California, Berkeley]  \n",
       "\n",
       "[75 rows x 7 columns]"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.DataFrame(award_winners)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The names of all award winners are (alphabetical order): \n",
      "\n",
      "Adi Shamir, Alan Kay, Alan Perlis, Alfred Aho, Allen Newell, Amir Pnueli, Andrew Yao, Barbara Liskov, Bob Kahn, Butler Lampson, Charles Bachman, Charles P. Thacker, Dana Scott, David Patterson (computer scientist), Dennis Ritchie, Donald Knuth, Douglas Engelbart, E. Allen Emerson, Edgar F. Codd, Edmund M. Clarke, Edsger W. Dijkstra, Edward Feigenbaum, Edwin Catmull, Fernando J. Corbató, Frances Allen, Fred Brooks, Geoffrey Hinton, Herbert A. Simon, Ivan Sutherland, Jack Dongarra, James H. Wilkinson, Jeffrey Ullman, Jim Gray (computer scientist), John Backus, John Cocke (computer scientist), John Hopcroft, John L. Hennessy, John McCarthy (computer scientist), Joseph Sifakis, Judea Pearl, Juris Hartmanis, Ken Thompson, Kenneth E. Iverson, Kristen Nygaard, Leonard Adleman, Leslie Lamport, Leslie Valiant, Manuel Blum, Martin Hellman, Marvin Minsky, Maurice Wilkes, Michael O. Rabin, Michael Stonebraker, Niklaus Wirth, Ole-Johan Dahl, Pat Hanrahan, Peter Naur, Raj Reddy, Richard E. Stearns, Richard Hamming, Richard M. Karp, Robert Tarjan, Robert W. Floyd, Robin Milner, Ron Rivest, Shafi Goldwasser, Silvio Micali, Stephen Cook, Tim Berners-Lee, Tony Hoare, Vint Cerf, Whitfield Diffie, William Kahan, Yann LeCun, Yoshua Bengio.\n"
     ]
    }
   ],
   "source": [
    "print(\"The names of all award winners are (alphabetical order): \\n\\n{}.\".format(\", \".join(sorted(award_winners[\"name\"]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "award_winners_intro = pd.DataFrame(award_winners[\"intro\"], columns = [\"intro\"])\n",
    "award_winners_intro[\"winner_name\"] = np.nan\n",
    "award_winners_intro[\"count_words\"] = np.nan\n",
    "award_winners_intro[\"count_sentences\"] = np.nan\n",
    "award_winners_intro[\"count_paragraphs\"] = np.nan\n",
    "award_winners_intro[\"common_words\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "award_winners_intro[\"winner_name\"] = award_winners[\"name\"]\n",
    "award_winners_intro[\"count_words\"] = award_winners_intro[\"intro\"].apply(lambda x: len(word_tokenize(x)))\n",
    "award_winners_intro[\"count_sentences\"] = award_winners_intro[\"intro\"].apply(lambda x: len(sent_tokenize(x)))\n",
    "award_winners_intro[\"count_paragraphs\"] = award_winners_intro[\"intro\"].apply(lambda x: len(x.split(\"\\n\")))\n",
    "award_winners_intro[\"common_words\"] = award_winners_intro[\"intro\"].apply(lambda x: FreqDist(x.split()).most_common(10)).apply(lambda x: [i[0] for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(a, 2), (a, 2)\n"
     ]
    }
   ],
   "source": [
    "a = [(\"a\", 2),(\"a\", 2)]\n",
    "print(\", \".join([\"({}, {})\".format(i[0],i[1]) for i in a]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intro</th>\n",
       "      <th>winner_name</th>\n",
       "      <th>count_words</th>\n",
       "      <th>count_sentences</th>\n",
       "      <th>count_paragraphs</th>\n",
       "      <th>common_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sir Timothy John Berners-Lee  (born 8 June 195...</td>\n",
       "      <td>Tim Berners-Lee</td>\n",
       "      <td>359</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>(the, 36), (of, 21), (and, 14), (He, 11), (a, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yoshua Bengio  (born March 5, 1964) is a Canad...</td>\n",
       "      <td>Yoshua Bengio</td>\n",
       "      <td>91</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>(and, 6), (the, 5), (of, 4), (for, 3), (Bengio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Geoffrey Everest Hinton  (born 6 December 1947...</td>\n",
       "      <td>Geoffrey Hinton</td>\n",
       "      <td>181</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>(the, 12), (and, 8), (of, 7), (for, 5), (in, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Donald Ervin Knuth ( kə-NOOTH; born January 10...</td>\n",
       "      <td>Donald Knuth</td>\n",
       "      <td>184</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>(the, 20), (of, 13), (and, 11), (Knuth, 5), (c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Richard Manning Karp (born January 3, 1935) is...</td>\n",
       "      <td>Richard M. Karp</td>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>(in, 6), (and, 5), (the, 5), (of, 5), (for, 3)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Fernando José \"Corby\" Corbató (July 1, 1926 – ...</td>\n",
       "      <td>Fernando J. Corbató</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(a, 2), (Fernando, 1), (José, 1), (\"Corby\", 1)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Charles William Bachman III (December 11, 1924...</td>\n",
       "      <td>Charles Bachman</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>(his, 3), (Bachman, 2), (was, 2), (an, 2), (in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Butler W. Lampson, ForMemRS, (born December 23...</td>\n",
       "      <td>Butler Lampson</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(Butler, 1), (W., 1), (Lampson,, 1), (ForMemRS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Ole-Johan Dahl (12 October 1931 – 29 June 2002...</td>\n",
       "      <td>Ole-Johan Dahl</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>(of, 4), (Dahl, 2), (was, 2), (a, 2), (compute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Charles Patrick \"Chuck\" Thacker (February 26, ...</td>\n",
       "      <td>Charles P. Thacker</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>(computer, 2), (the, 2), (Charles, 1), (Patric...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                intro          winner_name  \\\n",
       "0   Sir Timothy John Berners-Lee  (born 8 June 195...      Tim Berners-Lee   \n",
       "1   Yoshua Bengio  (born March 5, 1964) is a Canad...        Yoshua Bengio   \n",
       "2   Geoffrey Everest Hinton  (born 6 December 1947...      Geoffrey Hinton   \n",
       "3   Donald Ervin Knuth ( kə-NOOTH; born January 10...         Donald Knuth   \n",
       "4   Richard Manning Karp (born January 3, 1935) is...      Richard M. Karp   \n",
       "..                                                ...                  ...   \n",
       "70  Fernando José \"Corby\" Corbató (July 1, 1926 – ...  Fernando J. Corbató   \n",
       "71  Charles William Bachman III (December 11, 1924...      Charles Bachman   \n",
       "72  Butler W. Lampson, ForMemRS, (born December 23...       Butler Lampson   \n",
       "73  Ole-Johan Dahl (12 October 1931 – 29 June 2002...       Ole-Johan Dahl   \n",
       "74  Charles Patrick \"Chuck\" Thacker (February 26, ...   Charles P. Thacker   \n",
       "\n",
       "    count_words  count_sentences  count_paragraphs  \\\n",
       "0           359               17                 4   \n",
       "1            91                4                 2   \n",
       "2           181                8                 3   \n",
       "3           184                8                 3   \n",
       "4            92                3                 2   \n",
       "..          ...              ...               ...   \n",
       "70           28                1                 1   \n",
       "71           56                2                 1   \n",
       "72           27                1                 1   \n",
       "73           44                2                 1   \n",
       "74           35                2                 1   \n",
       "\n",
       "                                         common_words  \n",
       "0   (the, 36), (of, 21), (and, 14), (He, 11), (a, ...  \n",
       "1   (and, 6), (the, 5), (of, 4), (for, 3), (Bengio...  \n",
       "2   (the, 12), (and, 8), (of, 7), (for, 5), (in, 5...  \n",
       "3   (the, 20), (of, 13), (and, 11), (Knuth, 5), (c...  \n",
       "4   (in, 6), (and, 5), (the, 5), (of, 5), (for, 3)...  \n",
       "..                                                ...  \n",
       "70  (a, 2), (Fernando, 1), (José, 1), (\"Corby\", 1)...  \n",
       "71  (his, 3), (Bachman, 2), (was, 2), (an, 2), (in...  \n",
       "72  (Butler, 1), (W., 1), (Lampson,, 1), (ForMemRS...  \n",
       "73  (of, 4), (Dahl, 2), (was, 2), (a, 2), (compute...  \n",
       "74  (computer, 2), (the, 2), (Charles, 1), (Patric...  \n",
       "\n",
       "[75 rows x 6 columns]"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "award_winners_intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intro</th>\n",
       "      <th>winner_name</th>\n",
       "      <th>count_words</th>\n",
       "      <th>count_sentences</th>\n",
       "      <th>count_paragraphs</th>\n",
       "      <th>common_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Joseph Sifakis (Greek: Ιωσήφ Σηφάκης) is a Gre...</td>\n",
       "      <td>Joseph Sifakis</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[Joseph, Sifakis, (Greek:, Ιωσήφ, Σηφάκης), is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                intro     winner_name  \\\n",
       "68  Joseph Sifakis (Greek: Ιωσήφ Σηφάκης) is a Gre...  Joseph Sifakis   \n",
       "\n",
       "    count_words  count_sentences  count_paragraphs  \\\n",
       "68           31                2                 1   \n",
       "\n",
       "                                         common_words  \n",
       "68  [Joseph, Sifakis, (Greek:, Ιωσήφ, Σηφάκης), is...  "
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "award_winners_intro[award_winners_intro[\"winner_name\"] == \"Joseph Sifakis\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Sub-activity: Applying NLP operations on the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Finding synonyms and antonyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4 Bigrams and trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Sub-section: Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Barplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
